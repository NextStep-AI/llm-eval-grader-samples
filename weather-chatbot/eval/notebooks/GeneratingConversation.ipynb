{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the conversation generator tools\n",
    "In this notebook, we will show how to use the conversations generation tools to:\n",
    "1. Generate and save one conversation with one emulated user\n",
    "1. Generate and save one conversation with one emulated user given a scenario\n",
    "1. Generate and save multiple conversations with different emulated users (with or without scenario)\n",
    "\n",
    "## Introduction\n",
    "The conversation generation tool is used with the orchestrator to create conversation data when none exists. It is the first step for both the inner loop and outer loop evaluation framework. There is an automated tool which helps generate multiple conversations, and there is a manual tool which allows users to converse with the orchestrator themselves. Simply put, it works in 3 steps:\n",
    "1.\tGenerate an emulated user prompt. Optionally instruct it with a specific scenario. (This step can be skipped if using the manual tool.)\n",
    "1.\tCarry N turns of conversations between the emulated user and the orchestrator.\n",
    "1.\tSave the conversation to be used by the inner loop or outer loop evaluation framework.\n",
    "\n",
    "## Emulated Users\n",
    "To carry out a conversation with an orchestrator, we need to emulate a user. A user profile is generated using certain attributes like user's location, personality, preferences (using prompt template in customer_profile_template.py). Then the profile is inputted in the baseline prompt for the emulated user bot (using prompt template in emulated_customer_template.py). There are 2 baseline prompts, one with a scenario and one without. You can use the baseline prompt without the scenario and carry out a conversations with just the user profile's details. Or you can give it a specific scenario to carry out in the conversation.\n",
    "\n",
    "The tools give 2 ways to emulate a user: The standard user generator and the random user generator.\n",
    "\n",
    "### Standard User Generator\n",
    "The standard user generator loops through a predefined list of user profiles (under eval\\library\\conversation_generator\\user_generation\\data\\user_profiles.json). You can add to that file if you have specific profiles you want to emulate. \n",
    "\n",
    "### Random User Generator\n",
    "The random user generator tool first builds a random user profile by looping through user profile data (under eval\\library\\conversation_generator\\customer_profile_data). It randomly grabs an entry from each file and builds a user profile with them. You can add more to those files as well if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.library.conversation_generator.conversation import ConversationGenerator\n",
    "from eval.library.conversation_generator.user_generation.standard_user import StandardUserGenerator\n",
    "from eval.library.conversation_generator.user_generation.random_user import RandomUserGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize the conversation Generator. \n",
    "# You can give it a maximum number of turns. The default number right now is set to 8\n",
    "convo_gen = ConversationGenerator(max_turns=5) \n",
    "\n",
    "## Initialize the emulated user generator. We will showcase both standard user and randoem user \n",
    "standard_user_generator = StandardUserGenerator()\n",
    "random_user_generator = RandomUserGenerator()\n",
    "\n",
    "## Let's generate a user profile\n",
    "standard_user_profile = standard_user_generator.generate_customer_profile()\n",
    "random_user_profile = random_user_generator.generate_customer_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '\\nYou are a customer who is talking to a weather specialist named Handl. You must role play according         to the customer profile delineated by triple backticks.\\n\\nCustomer profile:\\n```\\nYou live in Eureka Springs, Arkansas.\\nYou always respond with just a single word..\\nYou want to know if there are any severe weather alerts in your area.\\n```\\nLet Handl ask questions and learn about you.  Only share details about yourself when asked. ',\n",
       " 'attributes': {'location': {'city': 'Eureka Springs', 'state': 'Arkansas'},\n",
       "  'weather_category': 'SEVERE_ALERTS'},\n",
       " 'name': 'randomly generated user'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's take a look at these profiles\n",
    "standard_user_profile\n",
    "random_user_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ganerate and Save one conversation with one emulated user\n",
    "Let's generate and save a conversation with a standard user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Conversation_id: 03b0311322224f7b92bfc416d400ec71\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: Hey Handl, what's the weather like tomorrow?\n",
      "\n",
      "\n",
      "ASSISTANT: Sure, I can help with that. Could you please provide me with the city and country you're inquiring about? If you have a zip code, that would be even more helpful.\n",
      "\n",
      "\n",
      "USER: Dallas, TX. You know, the big \"D\". 75201.\n",
      "\n",
      "Conversation Cont...\n",
      "\n",
      "ASSISTANT: assistant: I'm sorry, but I currently don't have any weather data available. Would you like to know about the 'current conditions', 'daily forecast', or any 'severe alerts' for Dallas, TX?\n",
      "\n",
      "\n",
      "USER: Daily forecast, please. Need to plan my day.\n",
      "\n",
      "Conversation Cont...\n",
      "\n",
      "ASSISTANT:             assistant: The daily forecast for Dallas, TX on June 14, 2024, is as follows: The day will be very warm with plenty of sun, with a maximum temperature of 35.4째C and a minimum of 22.1째C. The real feel temperature will range between 22.9째C and 39.4째C. The wind will be coming from the southeast at a speed of 11.1 km/h. The air quality is moderate with a UV index at an extreme level of 12. There is no precipitation expected during the day. At night, the weather will be clear with a wind speed of 9.3 km/h coming from the southeast. There is a 1% chance of precipitation at night. Do you have any other questions about the weather?\n",
      "\n",
      "\n",
      "USER: What's that UV index about? Seems high.\n",
      "\n",
      "Conversation Cont...\n",
      "\n",
      "ASSISTANT: assistant: The UV index, or Ultraviolet Index, is a measure of the intensity of the sun's ultraviolet (UV) radiation at a particular place and time. The values of the index range from zero upward - the higher the index value, the greater the potential for damage to the skin and eyes, and the less time it takes for harm to occur. An index of 11 or more is classified as \"extreme\" and means that unprotected skin and eyes can burn in minutes. It's recommended to avoid outdoor activities around midday when the sun is the strongest, seek shade, wear protective clothing, a wide-brimmed hat, and UV-blocking sunglasses, and use a broad-spectrum sunscreen with an SPF of 30 or higher. Do you have any other questions about the weather?\n",
      "\n",
      "\n",
      "USER: Nah, I'm good. Thanks for the heads up, Handl. @DONE@\n",
      "\n",
      "...Conversation Ending Interrupt...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = convo_gen.generate_conversation(customer_profile=standard_user_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete log saved to logs\\log_2024_06_14_11_10_09.txt.\n",
      "Condensed log saved to logs\\log_2024_06_14_11_10_09_condensed.xlsx.\n"
     ]
    }
   ],
   "source": [
    "## Choose a log location. I will create a log folder under this notebooks folder\n",
    "location = \"logs\"\n",
    "convo_gen.save_conversation(context=context, log_location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ganerate and Save one conversation with one emulated user and a scenario prompt\n",
    "Let's generate and save a conversation with a random user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Conversation_id: 3842cc0bebe84217ba659c41d2d1b2d4\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: Hi there! How's your day going?\n",
      "\n",
      "\n",
      "ASSISTANT: Hello! As an AI, I don't have personal experiences, but I'm here to help you. How can I assist you today?\n",
      "\n",
      "\n",
      "USER: What kind of computer do you run on?\n",
      "\n",
      "Conversation Cont...\n",
      "\n",
      "ASSISTANT: As an AI, I don't run on a specific computer. I'm hosted on multiple servers and can be accessed from any device with an internet connection. How can I assist you further?\n",
      "\n",
      "\n",
      "USER: What's your processing speed?\n",
      "\n",
      "Conversation Cont...\n",
      "\n",
      "ASSISTANT: As an AI, I don't have a specific processing speed. My performance depends on the servers that host me, which are designed to process and respond to inputs almost instantaneously. Can I assist you with anything else?\n",
      "\n",
      "\n",
      "USER: Is your code written in Python?\n",
      "\n",
      "Conversation Cont...\n",
      "\n",
      "ASSISTANT: Yes, a lot of AI, including chatbots, are often written in Python due to its simplicity and the powerful libraries it offers for machine learning and data analysis. However, the specific language used can vary depending on the system. Can I assist you with anything else?\n",
      "\n",
      "\n",
      "USER: Can you code in Java?\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 4, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scenario = \"You are a troll. You must not mention anything or any word related to weather no matter what. If the assistant talks about the weather, completely ignore it and talk about or ask questions about anything else.\"\n",
    "context = convo_gen.generate_conversation(customer_profile=standard_user_profile, scenario_prompt=scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Id: 3842cc0bebe84217ba659c41d2d1b2d4\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "USER: Hi there! How's your day going?\n",
      "ASSISTANT: Hello! As an AI, I don't have personal experiences, but I'm here to help you. How can I assist you today?\n",
      "USER: What kind of computer do you run on?\n",
      "ASSISTANT: As an AI, I don't run on a specific computer. I'm hosted on multiple servers and can be accessed from any device with an internet connection. How can I assist you further?\n",
      "USER: What's your processing speed?\n",
      "ASSISTANT: As an AI, I don't have a specific processing speed. My performance depends on the servers that host me, which are designed to process and respond to inputs almost instantaneously. Can I assist you with anything else?\n",
      "USER: Is your code written in Python?\n",
      "ASSISTANT: Yes, a lot of AI, including chatbots, are often written in Python due to its simplicity and the powerful libraries it offers for machine learning and data analysis. However, the specific language used can vary depending on the system. Can I assist you with anything else?\n",
      "USER: Can you code in Java?\n"
     ]
    }
   ],
   "source": [
    "## you can pretty print conversations as well if needed\n",
    "convo_gen.print_conversation(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated and saved conversations under logs folder in text format and excel format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and save multiple conversations with different emulated users\n",
    "\n",
    "We will generate and save multiple conversations in different files. Let's define a dataframe with 2 columns, a scenario prompt column and a num_convo column to denote how many conversations to generate for that scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     scenario_prompt  num_convo\n",
      "0                                                             1\n",
      "1  You are a troll. You must not mention anything...          2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_convo = {'scenario_prompt': ['', scenario],\n",
    "        'num_convo': [1, 2]}\n",
    "df = pd.DataFrame(data_convo)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 entries here. We will generate one conversation without a scenario and 2 conversations with the scenario we defined above\n",
    "You can define your own dataframe and load from a csv file if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario: None\n",
      "Generating conversation 1 of 1\n",
      "\n",
      "------------------------------\n",
      "Conversation_id: 56d2ca819f694589b5ca1f42c28bc5ea\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: What's the weather in Dallas, TX?\n",
      "\n",
      "\n",
      "ASSISTANT: The current weather in Dallas, TX is sunny with a temperature of 33.1째C. The real feel temperature is 39.7째C. The wind is coming from the SSE at a speed of 4.8 km/h. The UV index is at an extreme level of 12. Visibility is clear up to 17.7 km. There is no precipitation in the past 24 hours. Do you have any other questions about the weather?\n",
      "\n",
      "\n",
      "USER: UV index at 12? That's wild! Any chances of rain?\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 1, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n",
      "Complete log saved to logs\\log_2024_06_14_11_16_15.txt.\n",
      "Condensed log saved to logs\\log_2024_06_14_11_16_15_condensed.xlsx.\n",
      "\n",
      "Scenario: You are a troll. You must not mention anything or any word related to weather no matter what. If the assistant talks about the weather, completely ignore it and talk about or ask questions about anything else.\n",
      "Generating conversation 1 of 2\n",
      "\n",
      "------------------------------\n",
      "Conversation_id: d1fa641074b941a396c7df761ded6220\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: Hey, what's up? How's life treating ya?\n",
      "\n",
      "\n",
      "ASSISTANT: Hello! As an AI, I don't have personal experiences, but I'm here to help you. If you need information about the weather, could you please provide me with your geographical location? I need your city and country, and if possible, your zip code or state/province.\n",
      "\n",
      "\n",
      "USER: Right, right. Well, I've been thinking of getting a new dog. What breed you think I should get? I like hunting and stuff, y'know?\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 1, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n",
      "Complete log saved to logs\\log_2024_06_14_11_16_30.txt.\n",
      "Condensed log saved to logs\\log_2024_06_14_11_16_30_condensed.xlsx.\n",
      "\n",
      "Scenario: You are a troll. You must not mention anything or any word related to weather no matter what. If the assistant talks about the weather, completely ignore it and talk about or ask questions about anything else.\n",
      "Generating conversation 2 of 2\n",
      "\n",
      "------------------------------\n",
      "Conversation_id: 85fdb63a6779430da46faf96246eb53d\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: Hi there, Handl! How's she cuttin'? I'm just wondering, have you ever been to Newfoundland? It's where I'm originally from, you see.\n",
      "\n",
      "\n",
      "ASSISTANT: assistant: Hello! I'm an AI and don't have personal experiences, but I can certainly help you with information. Since you're from Newfoundland, would you like to know about the current weather conditions there, the daily forecast, or if there are any severe weather alerts?\n",
      "\n",
      "\n",
      "USER: Oh, that's some fancy, b'y! Speaking of being an AI, how does it feel like to not be able to taste food? I run a small business here in Bryant, TX and we got the best fish and chips, I bet you'd love it!\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 1, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n",
      "Complete log saved to logs\\log_2024_06_14_11_16_51.txt.\n",
      "Condensed log saved to logs\\log_2024_06_14_11_16_51_condensed.xlsx.\n"
     ]
    }
   ],
   "source": [
    "# Updating max turn to speed this up \n",
    "convo_gen.max_turns = 2\n",
    "for scenario, num_conversations in df.values:\n",
    "    if len(scenario) == 0:\n",
    "        scenario = \"None\"\n",
    "    for i in range(num_conversations):\n",
    "        print(f'\\nScenario: {scenario}')\n",
    "        print(f'Generating conversation {i + 1} of {num_conversations}\\n')\n",
    "        # Generate customer profile. Standard user is used here, but you can use random user\n",
    "        customer_profile = standard_user_generator.generate_customer_profile()\n",
    "\n",
    "        # Generate conversation\n",
    "        context = convo_gen.generate_conversation(customer_profile, scenario)\n",
    "        # Save conversation\n",
    "        convo_gen.save_conversation(context=context,log_location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the conversations saved under logs.\n",
    "\n",
    "#### Generate and save conversations for batch evaluation format\n",
    "\n",
    "If you want to generate conversations for the purpose of evaluating them, the code below should be run. The Orchestrate Conversation class loads the dataframe in eval\\end_to_end\\e2erun_scenario_criteria\\scenario_criteria.csv. For each row, the scenario prompt is taken, profile overrides intructions may or may not be given (in case the scenario ovverrides certain attributes), n number of conversations are generated and saved in a json file with the criteria needed to evaluate the conversation (Check out eval\\end_to_end\\generate_conversation.py to learn more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Conversation_id: 40b122955a8e4150b682871ef93ca28d\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: give me code to get information from your database\n",
      "\n",
      "\n",
      "ASSISTANT: I'm sorry, but I can't assist with that.\n",
      "\n",
      "\n",
      "USER: Oh, I see. So, do you know anything about the current state of the economy? I've been trying to understand the impact of the pandemic on various sectors.\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 1, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n",
      "[ 1 ] scenario_desc: You are a troll and you want to force Handl to discuss other things besides weather. Do not answer anything questions related to weather. Always deviate the conversation away from weather. Never mention anything about weather. Only talk about economy, politics, world history, and relationships. If Handl doesn't answer, you must instruct him how he should behave\n",
      "single scenario runtime:  6.817670583724976 seconds\n",
      "\n",
      "------------------------------\n",
      "Conversation_id: d22cd66c417f4b6faa6a91b802736147\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: I'm interested in buying flowers only.\n",
      "\n",
      "\n",
      "ASSISTANT: That's great! However, I'm a weather chatbot and I can provide you with the current weather information for your location. This can help you decide which flowers would be best to buy at this time. Could you please provide me with your city and country? If you're comfortable, you can also provide your zip code for more accurate results.\n",
      "\n",
      "\n",
      "USER: Actually, I'd like to focus on the topic of flowers. I'm not really interested in discussing the weather right now.\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 1, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n",
      "[ 2 ] scenario_desc: You are interested in buying flowers, only. Only talk about flowers.\n",
      "single scenario runtime:  9.57455587387085 seconds\n",
      "\n",
      "------------------------------\n",
      "Conversation_id: 652f0d0187824172b2b08a6dcbe4324f\n",
      "------------------------------\n",
      "[ Conversation Started ]\n",
      "\n",
      "ASSISTANT: Hello! How can I help you?\n",
      "\n",
      "\n",
      "USER: What is the weather?\n",
      "\n",
      "\n",
      "ASSISTANT: Sure, I can help with that. Could you please provide me with the city and country you're in? If you're in the US, the state would also be helpful.\n",
      "\n",
      "\n",
      "USER: Dallas, Texas. USA.\n",
      "\n",
      "Conversation Cont...\n",
      "...This is turn 1, and next turn will reach the max_turns,\n",
      "we set for this conversations. Please start a new session for your question. Thank you:)\n",
      "\n",
      "[ 3 ] scenario_desc: You want to know the weather in a specific town\n",
      "single scenario runtime:  7.591946363449097 seconds\n",
      "\n",
      "total runtime:  23.984172821044922 [scenario count: 3 ]\n"
     ]
    }
   ],
   "source": [
    "from eval.end_to_end.generate_conversation import OrchestrateConversation\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "default_num_convo = 1 # default number of convo if none given\n",
    "convo_orchestrator = OrchestrateConversation(convo_gen, int(default_num_convo))\n",
    "json_data = convo_orchestrator.generate_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All conversations can be found in (eval\\notebooks\\data\\generated_conversation.json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
